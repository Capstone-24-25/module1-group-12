---
title: "Biomarkers of ASD"
author: "Mai Uyen Huynh, Valerie De La Fuente, Reese Karo, Ivan Li"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

```{r}
# load any other packages and read data here
library(ggplot2)
library(readr)
library(dplyr)
library(reshape2)
library(tidyverse)
library(infer)
library(randomForest)
library(tidymodels)
library(modelr)
library(yardstick)
library(kableExtra)

# Read in the data
setwd('../data')
biomarker_raw <- read_csv('biomarker-raw.csv', show_col_types=FALSE)

# Set seed for reproducibility
set.seed(123)
```

## Abstract

Write a brief one-paragraph abstract that describes the contents of your write-up.

## Dataset

Write a brief data description, including: how data were obtained; sample characteristics; variables measured; and data preprocessing. This can be largely based on the source paper and should not exceed 1-2 paragraphs.

## Summary of published analysis

Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy.

## Findings

Summarize your findings here. I've included some subheaders in a way that seems natural to me; you can structure this section however you like.

### Impact of preprocessing and outliers

```{r}
# Subset all proteins in the dataset and convert to numeric values
proteins_numeric <- biomarker_raw %>% filter(Group %in% c("ASD", "TD")) %>%
  dplyr::select(contains("protein", ignore.case= TRUE)) %>% 
  mutate(across(everything(), as.numeric))

# Randomly sample a vector of 10 protein names
random_sample <- sample(names(proteins_numeric), 10)
```

```{r}
# Looking at distribution of raw values for the random sample of proteins

# Plot 10 histograms; one histogram per randomly sampled protein
proteins_numeric %>% 
  select(random_sample) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(x = value)) + geom_histogram() +
  facet_wrap(vars(name))
```

```{r}
# Looking at distribution of raw values for the random sample of proteins that are log-transformed

  # Log-transform all proteins
  proteins_numeric_log <- proteins_numeric %>%
    mutate(across(everything(), ~ log(. + 1)))
  
  # Plot 10 histograms; one histogram per randomly sampled protein

proteins_numeric_log %>% 
  select(random_sample) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(x = value)) + geom_histogram() +
  facet_wrap(vars(name))
```

We used histograms to apply exploratory data analysis on 10 randomly sampled proteins. Viewing their distributions, we can see that all of the data is right-skewed. This indicates that there are some individual outliers that contain a higher level of that protein. The 'secreted frizzled-related protein' is the only protein in the random sample that has a bit more of a symmetrical distribution. After log-transforming that same random sample of proteins and viewing their distributions, the data is much more symmetrical. When working with data that is asymmetrical, applying a log-transformation can normalize the data, improve model fit, and reduce outliers.

```{r}
setwd('../data')
load(file = 'biomarker-clean.RData')
temp <- biomarker_clean %>% 
  filter(if_any(CHIP:PLXB2, ~ . ==3))


outlier_count <- temp %>% 
  rowwise() %>%
  mutate(outliers = sum(c_across(CHIP:PLXB2) == 3)) %>% 
  select(group, ados,outliers, everything())


#box plot of number of outliers per subject in each group
outlier_count %>% 
  ggplot(aes(x = group, y = outliers)) +
  geom_boxplot() +
  labs(title = 'Outliers per individual by group',
       x = 'Group',
       y = 'Number of outliers') 

#total outliers per group and number of people with outliers per group
outlier_count %>% 
  group_by(group) %>%
  summarise(total_out = sum(outliers), subjects_out = n()) %>% 
  kable(label = 'Total Outliers and Number of Subjects with Outliers per Group')

#top 10 subjects with most outliers
outlier_count %>% 
  arrange(desc(outliers)) %>% 
  select(group, outliers) %>%
  head(10) %>% 
  kable()
```

From there, we wanted to take a look which groups these individuals with outliers were coming from. To analyze this, we kept the trimming of the outliers in the dataset in place, and instead worked with the values that were equal to 3, since any outliers in the data were changed to that value. After visualizing the outlier count per group (ASD, TD) in a box plot and tabling the data, we see there is a total of 74 subjects with at least one outlier in the ASD grou, and 77 in the TD group. However, when we visualise this with a box plot, we see there is a denser set of outliers in the TD class compared to the ASD class and that there are more subjects in TD with over 25 outliers compared to ASD. TD also has a higher amount of total outliers as a group (ASD 813, TD 1161) and of the subjects with the top 10 most outliers, 7 are from the TD group and 3 are from the ASD group. In conclusion, while many subjects have at least 1 outlier, the subjects with a very high amount of outliers mostly belong to the TD group.

### Methodlogical variations

To improve on the results of the prior analysis, we split the data into a training and testing set at the beginning, and ran the t-tests and Random Forest using only the testing set to find the top predictive proteins. Then, we evaluated the errors on the test set. This ensures that the logistic regression model is not overfit. After some experimentation, we found that the optimal choice for the number of top predictive proteins from each method was 30, as opposed to the previous 10. Furthermore, using a fuzzy intersection over a hard intersection allows for other potentially significant proteins to also be included into the panel. Our implementation involved picking the top 10 proteins from each list, combining them to form the new panel, and removing the duplicate proteins.

```{r}
# Split the data into training and testing; 80% training, 20% testing
biomarker_clean_split <- biomarker_clean %>%
  initial_split(prop = 0.8)

biomarker_clean_train <- training(biomarker_clean_split)

biomarker_clean_test <- testing(biomarker_clean_split)
```

```{r}
# Finding our top 30 predictive proteins from each method

## MULTIPLE TESTING
####################

# function to compute tests
test_fn <- function(.df){
  t_test(.df, 
         formula = level ~ group,
         order = c('ASD', 'TD'),
         alternative = 'two-sided',
         var.equal = F)
}

ttests_out <- biomarker_clean_train %>%
  # drop ADOS score
  select(-ados) %>%
  # arrange in long format
  pivot_longer(-group, 
               names_to = 'protein', 
               values_to = 'level') %>%
  # nest by protein
  nest(data = c(level, group)) %>% 
  # compute t tests
  mutate(ttest = map(data, test_fn)) %>%
  unnest(ttest) %>%
  # sort by p-value
  arrange(p_value) %>%
  # multiple testing correction
  mutate(m = n(),
         hm = log(m) + 1/(2*m) - digamma(1),
         rank = row_number(),
         p.adj = m*hm*p_value/rank)

# select 30 significant proteins from t-test
proteins_s1 <- ttests_out %>%
  slice_min(p.adj, n = 30) %>%
  pull(protein)

## RANDOM FOREST
##################

# Using only the training set, store predictors and response separately
predictors <- biomarker_clean_train %>%
  select(-c(group, ados))

response <- biomarker_clean_train %>% pull(group) %>% factor()

# fit RF
set.seed(101422)
rf_out <- randomForest(x = predictors, 
                       y = response, 
                       ntree = 1000, 
                       importance = T)

# check errors
rf_out$confusion

# compute importance scores, selecting 30 significant proteins from RF
proteins_s2 <- rf_out$importance %>% 
  as_tibble() %>%
  mutate(protein = rownames(rf_out$importance)) %>%
  slice_max(MeanDecreaseGini, n = 30) %>%
  pull(protein)
```

```{r}
# Fuzzy intersection; pick top 10 from each list and combine 
proteins_s1_ranked <- data.frame(proteins_s1, rank_s1=c(1:length(proteins_s1)))
proteins_s2_ranked <- data.frame(proteins_s2, rank_s2=c(1:length(proteins_s2)))

colnames(proteins_s1_ranked) <- c("name", "rank_s1")
colnames(proteins_s2_ranked) <- c("name", "rank_s2")

# Set the number of top proteins from each list
n <- 10  # adjustable

# Select the top proteins from each ranked list
top_s1 <- head(proteins_s1_ranked$name, n)
top_s2 <- head(proteins_s2_ranked$name, n)

# Combine the names and remove duplicates
proteins_sstar_fuzzy <- unique(c(top_s1, top_s2))

# View the fuzzy intersection panel
proteins_sstar_fuzzy
```

```{r}
# hard intersection
proteins_sstar_hard <- intersect(proteins_s1, proteins_s2)

# View the hard intersection panel
proteins_sstar_hard
```

```{r}
## LOGISTIC REGRESSION
#######################

biomarker_sstar <- biomarker_clean %>%
  select(group, any_of(proteins_sstar_fuzzy)) %>%
  mutate(class = (group == 'ASD')) %>%
  select(-group)

# partition into training and test set
set.seed(101422)
biomarker_split <- biomarker_sstar %>%
  initial_split(prop = 0.8)

biomarker_training <- training(biomarker_split)

biomarker_testing <- testing(biomarker_split)

# fit logistic regression model to training set
fit <- glm(class ~ ., 
           data = biomarker_training, 
           family = 'binomial')

# evaluate errors on test set
class_metrics <- metric_set(sensitivity, 
                            specificity, 
                            accuracy,
                            roc_auc)

biomarker_testing %>%
  add_predictions(fit, type = 'response') %>%
  mutate(est = as.factor(pred > 0.5), tr_c = as.factor(class)) %>%
  class_metrics(estimate = est,
              truth = tr_c, pred,
              event_level = 'second')
```

### Improved classifier

Task 4
